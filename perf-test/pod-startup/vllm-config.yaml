# {{$namespace := DefaultParam .namespace "default"}}
# {{$deploymentReplicas:= DefaultParam .deploymentReplicas 1}}
# {{$modelName := DefaultParam .modelName "gpt2"}}
# {{$modelRepo := DefaultParam .modelName "openai-community/gpt2"}}
# {{$podReplicas := DefaultParam .podReplicas "1"}}

{{$namespace := DefaultParam .namespace "serverless-workstream"}}
{{$deploymentReplicas:= DefaultParam .deploymentReplicas 1}}
{{$modelName := DefaultParam .modelName "granite-3-0-2b-instruct"}}
{{$modelRepo := DefaultParam .modelName "ibm-granite/granite-3.0-3b-a800m-instruct"}}
{{$podReplicas := DefaultParam .podReplicas "1"}}


name: test
automanagedNamespaces: 0
namespace:
  number: 1

tuningSets:
- name: Uniform1qps
  qpsLoad:
    qps: 1

steps:
- name: Start measurements
  measurements:
  - Identifier: PodStartupLatency
    Method: PodStartupLatency
    Params:
      action: start
      labelSelector: performance = test
      threshold: 3600s
  - Identifier: WaitForControlledPodsRunning
    Method: WaitForControlledPodsRunning
    Params:
      action: start
      apiVersion: apps/v1
      kind: Deployment
      labelSelector: performance = test
      operationTimeout: 3600s
- name: Create VLLM deployment
  phases:
  - NamespaceList: 
    - {{$namespace}}
    replicasPerNamespace: {{$deploymentReplicas}}
    tuningSet: Uniform1qps
    objectBundle:
    - basename: {{$modelName}}
      objectTemplatePath: "vllm-pvc.yaml"
    - basename: {{$modelName}}
      objectTemplatePath: "vllm-deployment.yaml"
      templateFillMap:
        podReplicas: {{$podReplicas}}
        claimName: {{$modelName}}
        modelRepo: {{$modelRepo}}
    - basename: {{$modelName}}
      objectTemplatePath: "vllm-service.yaml"
- name: Wait for pods to be running
  measurements:
  - Identifier: WaitForControlledPodsRunning
    Method: WaitForControlledPodsRunning
    Params:
      action: gather
- name: Measure pod startup latency
  measurements:
  - Identifier: PodStartupLatency
    Method: PodStartupLatency
    Params:
      action: gather
